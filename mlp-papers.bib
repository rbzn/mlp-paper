%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for rob at 2013-03-24 14:17:02 +0100 


%% Saved with string encoding Unicode (UTF-8) 


@article{Aizawa2013,
author = {Aizawa, A},
file = {:C$\backslash$:/Users/Moritz/Desktop/05-NTCIR10-MATH-TopicG.pdf:pdf},
journal = {research.nii.ac.jp},
keywords = {description extraction,mathematical formula search,mathml indexing,support vector machine},
pages = {680--685},
title = {{The MCAT Math Retrieval System for NTCIR-10 Math Track}},
year = {2013}
}

@inproceedings{overview,
address = {Tokyo, Japan},
author = {Aizawa, Akiko and Kohlhase, Michael and Ounis, Iadh},
booktitle = {Proceedings of the 10th NTCIR Conference on Evaluation of Information Access Technologies},
file = {:C$\backslash$:/Users/Moritz/Desktop/01-NTCIR10-OV-MATH-AizawaA.pdf:pdf},
keywords = {content,information access to mathematical,mathml,top},
pages = {654--661},
title = {{NTCIR-10 Math Pilot Task Overview}},
year = {2013}
}
@article{Oommen2008,
	Author = {Oommen, Thomas and Misra, Debasmita and Twarakavi, NavinK.C. and Prakash, Anupma and Sahoo, Bhaskar and Bandopadhyay, Sukumar},
	Date-Added = {2013-03-24 13:15:42 +0000},
	Date-Modified = {2013-03-24 13:15:42 +0000},
	Doi = {10.1007/s11004-008-9156-6},
	Issn = {1874-8961},
	Issue = {4},
	Journal = {Mathematical Geosciences},
	Keywords = {Remote sensing; Support vector machines; Maximum likelihood; Multispectral; Hyperspectral classification},
	Language = {English},
	Pages = {409-424},
	Publisher = {Springer-Verlag},
	Title = {An Objective Analysis of Support Vector Machine Based Classification for Remote Sensing},
	Url = {http://dx.doi.org/10.1007/s11004-008-9156-6},
	Volume = {40},
	Year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s11004-008-9156-6}}

@article{Bunescu2006,
	Author = {Bunescu, R and Mooney, R},
	Date-Added = {2013-03-23 14:26:38 +0000},
	Date-Modified = {2013-03-23 14:27:00 +0000},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/erk-nips-05.pdf:pdf},
	Journal = {Advances in neural information processing \ldots},
	Title = {{Subsequence kernels for relation extraction}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.3817\&rep=rep1\&type=pdf},
	Year = {2006},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.3817%5C&rep=rep1%5C&type=pdf}}

@article{Bunescu2007,
	Author = {Bunescu, R and Mooney, R},
	Date-Added = {2013-03-23 14:26:18 +0000},
	Date-Modified = {2013-03-23 14:26:18 +0000},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/acl2007.pdf:pdf},
	Journal = {Annual meeting-association for \ldots},
	Title = {{Learning to extract relations from the web using minimal supervision}},
	Url = {http://acl.ldc.upenn.edu/P/P07/P07-1073.pdf},
	Year = {2007},
	Bdsk-Url-1 = {http://acl.ldc.upenn.edu/P/P07/P07-1073.pdf}}

@misc{github,
	Author = {Robert Pagel},
	Date-Added = {2013-03-16 13:20:27 +0000},
	Date-Modified = {2013-03-16 13:24:23 +0000},
	Howpublished = {\url{https://github.com/rbzn/project-mlp}},
	Title = {MLP Project Repository},
	Year = {2013}}

@misc{Rathna96,
	Author = {Adwait Ratnaparkhi},
	Date-Added = {2013-03-16 12:31:48 +0000},
	Date-Modified = {2013-03-16 12:31:48 +0000},
	Title = {A Maximum Entropy Model for Part-Of-Speech Tagging},
	Year = {1996}}

@article{Alexandrov2010,
	Author = {Alexandrov, Alexander and Battr\'{e}, Dominic and Ewen, Stephan and Heimel, Max and Hueske, Fabian and Kao, Odej and Markl, Volker and Nijkamp, Erik and Warneke, Daniel},
	Date-Added = {2013-03-16 11:54:36 +0000},
	Date-Modified = {2013-03-16 11:54:49 +0000},
	Issn = {2150-8097},
	Issue = {1-2},
	Issue_Date = {September 2010},
	Journal = {Proceedings of the VLDB Endowment},
	Month = {September},
	Pages = {1625--1628},
	Publisher = {VLDB Endowment},
	Title = {Massively Parallel Data Analysis with {PACTs} on {N}ephele},
	Volume = {3},
	Year = {2010}}

@book{Salton86,
	Address = {New York, NY, USA},
	Author = {Salton, Gerard and McGill, Michael J.},
	Date-Added = {2013-03-15 23:05:00 +0000},
	Date-Modified = {2013-03-15 23:05:25 +0000},
	Isbn = {0070544840},
	Publisher = {McGraw-Hill, Inc.},
	Title = {Introduction to Modern Information Retrieval},
	Year = {1986}}

@article{Agichtein2000,
	Author = {Agichtein, Eugene and Gravano, Luis},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/dl00.pdf:pdf},
	Title = {{Snowball : Extracting Relations from Large Plain-Text Collections}},
	Year = {2000}}

@article{Ben2000,
	Author = {Ben, Wahiba and Karaa, Abdessalem},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/1102.5728.pdf:pdf},
	Keywords = {information extraction,learning,named entity,tf-idf,web document},
	Pages = {1--8},
	Title = {{Named entity recognition using web document corpus}},
	Year = {2000}}

@article{Bharati,
	Abstract = {In this paper, we present the concept of Approximate grammar and how it can be used to extract information from a document. As the structure of informational strings cannot be defined well in a document, we cannot use the conventional grammar rules to represent the information. Hence, the need arises to design an approximate grammar than can be used effectively to accomplish the task of Information extraction. Approximate grammars are a novel step in this direction. The rules of an approximate grammar can be given by a user or the machine can learn the rules from an annotated document. We have performed our experiments in both the above areas and the results have been impressive.},
	Author = {Bharati, Akshar},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/0305004.pdf:pdf},
	Title = {{Approximate Grammar for Information Extraction Approximate Grammar for Information Extraction}}}

@article{Cahill2008,
	Author = {Cahill, Aoife},
	Doi = {10.1111/j.1749-818X.2007.00046.x},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/cahill.pdf:pdf},
	Issn = {1749-818X},
	Journal = {Language and Linguistics Compass},
	Month = jan,
	Number = {1},
	Pages = {36--58},
	Title = {{Treebank-Based Probabilistic Phrase Structure Parsing}},
	Url = {http://doi.wiley.com/10.1111/j.1749-818X.2007.00046.x},
	Volume = {2},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.1749-818X.2007.00046.x},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.1749-818X.2007.00046.x}}

@article{Klein2003,
	Abstract = {We discuss two named-entity recognition models which use characters and character n-grams either exclusively or as an important part of their data representation. The first model is a character-level HMM with minimal context information, and the second model is a maximum-entropy conditional markov model with substantially richer context features. Our best model achieves an overall F1 of 86.07\% on the English test data (92.31\% on the development data). This number represents a 25\% error reduction over the same model without word-internal (substring) features.},
	Author = {Klein, Dan and Smarr, Joseph and Manning, Christopher D},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/conll-ner.pdf:pdf},
	Pages = {4},
	Title = {{Named Entity Recognition with Character-Level Models}},
	Url = {http://nlp.stanford.edu/pubs/conll-ner.pdf},
	Year = {2003},
	Bdsk-Url-1 = {http://nlp.stanford.edu/pubs/conll-ner.pdf}}

@article{Liu,
	Author = {Liu, Yang and Shriberg, Elizabeth and Stolcke, Andreas and Member, Senior and Hillard, Dustin and Ostendorf, Mari and Harper, Mary},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/enrichspeech.pdf:pdf},
	Pages = {1--15},
	Title = {{Enriching Speech Recognition with Automatic Detection of Sentence Boundaries and Disfluencies}}}

@article{Mintz2008,
	Author = {Mintz, Mike and Bills, Steven and Snow, Rion and Jurafsky, Dan},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/mintz.pdf:pdf},
	Number = {2005},
	Title = {{Distant supervision for relation extraction without labeled data}},
	Year = {2008}}

@article{Pas2006,
	Author = {Pas, Marius and Durme, Benjamin Van and York, New},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/pascaIJCAI07.pdf:pdf},
	Pages = {2832--2837},
	Title = {{What You Seek is What You Get : Extraction of Class Attributes from Query Logs}},
	Year = {2006}}

@article{Quoc2010,
	Author = {Quoc, Minh Nghiem and Yokoi, Keisuke and Matsubayashi, Yuichiroh and Aizawa, Akiko},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/W10-3910.pdf:pdf},
	Number = {August},
	Pages = {69--74},
	Title = {{Mining coreference relations between formulas and text using Wikipedia}},
	Year = {2010}}

@article{Shadvar2012,
	Abstract = {During the past decades, to study high-dimensional data in a large variety of problems, researchers have proposed many Feature Extraction algorithms. One of the most effective approaches for optimal feature extraction is based on mutual information (MI). However it is not always easy to get an accurate estimation for high dimensional MI. In terms of MI, the optimal feature extraction is creating a feature set from the data which jointly have the largest dependency on the target class and minimum redundancy. In this paper, a component-by-component gradient ascent method is proposed for feature extraction which is based on one-dimensional MI estimates. We will refer to this algorithm as Mutual Information Feature Extraction (MIFX). The performance of this proposed method is evaluated using UCI databases. The results indicate that MIFX provides a robust performance over different data sets which are almost always the best or comparable to the best ones.},
	Author = {Shadvar, Ali},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/1207.3394.pdf:pdf},
	Keywords = {Classification,Dimension reduction,Feature extraction,Mutual information},
	Mendeley-Tags = {Classification,Dimension reduction,Feature extraction,Mutual information},
	Number = {3},
	Pages = {13--24},
	Title = {{Dimension Reduction by Mutual Information F EATURE E XTRACTION}},
	Url = {http://arxiv.org/pdf/1207.3394.pdf},
	Volume = {4},
	Year = {2012},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1207.3394.pdf}}

@article{Snoek2001,
	Abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a $\backslash$black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to ecient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the e ects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1206.2944v2},
	Author = {Snoek, By Jasper and Larochelle, Hugo and Adams, Ryan P},
	Eprint = {arXiv:1206.2944v2},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/1206.2944.pdf:pdf},
	Pages = {1--12},
	Title = {{PRACTICAL BAYESIAN OPTIMIZATION OF MACHINE LEARNING}},
	Url = {http://arxiv.org/pdf/1206.2944.pdf},
	Year = {2001},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1206.2944.pdf}}

@article{Sojka2008,
	Abstract = {This paper describes exploitation of semantic annotations in the design and architecture of MIaS (Math Indexer and Searcher) system for mathematics retrieval. Basing on the claim that navigational and research search are `killer' applications for digital library such as the European Digital Mathematics Library, EuDML, we argue for an approach based on Natural Language Processing techniques as used in corpus management systems such as the Sketch Engine, that will reach web scalability and avoid inference problems. The main ideas are 1) to augment surface texts (including math formulae) with additional linked representations bearing semantic information (expanded formulae as text, canonicalized text and subformulae) for indexing, including support for indexing structural information (expressed as Content MathML or other tree structures) and 2) use semantic user preferences to order found documents. The semantic enhancements of the MIaS system are being implemented as a math-aware search engine based on the state-of-the-art system Apache Lucene, with support for [MathML] tree indexing. Scalability issues have been checked against more than 400,000 arXiv documents.},
	Author = {Sojka, Petr},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/sojka-esair2012.pdf:pdf},
	Isbn = {9781450317177},
	Keywords = {digital mathematics libraries,information systems,math indexing and retrieval,mathematical content representation,mias,webmias},
	Title = {{Exploiting Semantic Annotations in Math Information Retrieval Categories and Subject Descriptors}},
	Year = {2008}}

@article{Toutanova1993,
	Author = {Toutanova, Kristina and Klein, Dan and Manning, Christopher D},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/tagging.pdf:pdf},
	Title = {{Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network}},
	Year = {1993}}

@article{Yokoi,
	Author = {Yokoi, Keisuke and Nghiem, Minh-quoc and Matsubayashi, Yuichiroh and Aizawa, Akiko},
	Date-Modified = {2013-03-17 16:10:36 +0000},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/n43a11.pdf:pdf},
	Title = {{Contextual Analysis of Mathematical Expressions for Advanced Mathematical Search}},
	Year = {2010}}

@article{Zhang2009,
	Address = {New York, New York, USA},
	Author = {Zhang, Yi and Tsai, Flora S.},
	Doi = {10.1145/1506250.1506256},
	File = {:Volumes/HDD/Users/rob/Documents/uni/dbpro/papers/10.1.1.169.1868.pdf:pdf},
	Isbn = {9781605584300},
	Journal = {Proceedings of the WSDM '09 Workshop on Exploiting Semantic Annotations in Information Retrieval - ESAIR '09},
	Keywords = {named entity recognition,ner,novelty detection,pos},
	Pages = {30},
	Publisher = {ACM Press},
	Title = {{Combining named entities and tags for novel sentence detection}},
	Url = {http://portal.acm.org/citation.cfm?doid=1506250.1506256},
	Year = {2009},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1506250.1506256},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1506250.1506256}}

@article{Zhu2009,
	Abstract = {AbstractSemi-supervised learning is a learning paradigm concerned with the study of how computers and natural systems such as humans learn in the presence of both labeled and unlabeled data. Traditionally, learning has been studied either in the unsupervised paradigm (e.g., clustering, outlier detection) where all the data are unlabeled, or in the supervised paradigm (e.g., classification, regression) where all the data are labeled. The goal of semi-supervised learning is to understand how combining labeled and unlabeled data may change the learning behavior, and design algorithms that take advantage of such a combination. Semi-supervised learning is of great interest in machine learning and data mining because it can use readily available unlabeled data to improve supervised learning tasks when the labeled data are scarce or expensive. Semi-supervised learning also shows potential as a quantitative tool to understand human category learning, where most of the input is self-evidently unlabeled. In this in...},
	Author = {Zhu, Xiaojin and Goldberg, Andrew B},
	Doi = {10.2200/S00196ED1V01Y200906AIM006},
	Editor = {Brachman, Ronald J and Dietterich, Thomas},
	Isbn = {9781598295474},
	Issn = {19394608},
	Journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	Number = {1},
	Pages = {1--130},
	Pmid = {12025367},
	Publisher = {Morgan \& Claypool Publishers},
	Series = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	Title = {{Introduction to Semi-Supervised Learning}},
	Url = {http://www.morganclaypool.com/doi/abs/10.2200/S00196ED1V01Y200906AIM006 http://books.google.de/books?id=c\_haJrQ0ScAC},
	Volume = {3},
	Year = {2009},
	Bdsk-Url-1 = {http://www.morganclaypool.com/doi/abs/10.2200/S00196ED1V01Y200906AIM006%20http://books.google.de/books?id=c%5C_haJrQ0ScAC},
	Bdsk-Url-2 = {http://dx.doi.org/10.2200/S00196ED1V01Y200906AIM006}}
